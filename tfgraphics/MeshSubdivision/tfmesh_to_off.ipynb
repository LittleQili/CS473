{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfmesh_to_off.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2Fj4S3r0p1A"
      },
      "source": [
        "##### Copyright 2019 Google LLC.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnasw-UIYBH2",
        "outputId": "760ca92d-851d-4fe0-b0d1-5459961e4080"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Okg-R95R1CaX"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x09idYC2vsZQ"
      },
      "source": [
        "# Mesh Segmentation using Feature Steered Graph Convolutions\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/graphics/blob/master/tensorflow_graphics/notebooks/mesh_segmentation_demo.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/graphics/blob/master/tensorflow_graphics/notebooks/mesh_segmentation_demo.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26AvKq8MJRGl"
      },
      "source": [
        "!pip install tensorflow_graphics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkPKOuyJKuKM"
      },
      "source": [
        "Now that TensorFlow Graphics and dependencies are installed, let's import everything needed to run the demos contained in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlBviBxue7n0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c6d044-6122-4cda-d69f-ba1327ad886e"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# from tensorflow_graphics.nn.layer import graph_convolution as graph_conv\n",
        "from tensorflow_graphics.notebooks import mesh_segmentation_dataio as dataio\n",
        "# from tensorflow_graphics.notebooks import mesh_viewer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGaDtH49dlJb"
      },
      "source": [
        "Note this notebook works best in Graph mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gh-ZSwXnB-5"
      },
      "source": [
        "### Fetch model files and data\n",
        "\n",
        "For convenience, we provide a pre-trained model. Let's now download a pre-trained model checkpoint and the test data. The meshes are generated using Unity Multipurpose Avatar system [UMA](https://assetstore.unity.com/packages/3d/characters/uma-2-unity-multipurpose-avatar-35611)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZkB3iIcvvzJ"
      },
      "source": [
        "path_to_model_zip = tf.keras.utils.get_file(\n",
        "    'model.zip',\n",
        "    origin='https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/model.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_data_zip = tf.keras.utils.get_file(\n",
        "    'data.zip',\n",
        "    origin='https://storage.googleapis.com/tensorflow-graphics/notebooks/mesh_segmentation/data.zip',\n",
        "    extract=True)\n",
        "\n",
        "local_model_dir = os.path.join(os.path.dirname(path_to_model_zip), 'model')\n",
        "test_data_files = [\n",
        "    os.path.join(\n",
        "        os.path.dirname(path_to_data_zip),\n",
        "        'data/Dancer_test_sequence.tfrecords')\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmh4b6VKcATt"
      },
      "source": [
        "## Load and visualize test data\n",
        "\n",
        "For graph convolutions, we need a *weighted adjacency matrix* denoting the mesh\n",
        "connectivity. Feature-steered graph convolutions expect self-edges in the mesh\n",
        "connectivity for each vertex, i.e. the diagonal of the weighted adjacency matrix\n",
        "should be non-zero. This matrix is defined as:\n",
        "```\n",
        "A[i, j] = w[i,j] if vertex i and vertex j share an edge,\n",
        "A[i, i] = w[i,i] for each vertex i,\n",
        "A[i, j] = 0 otherwise.\n",
        "where, w[i, j] = 1/(degree(vertex i)), and sum(j)(w[i,j]) = 1\n",
        "```\n",
        "Here degree(vertex i) is the number of edges incident on a vertex (including the\n",
        "self-edge). This weighted adjacency matrix is stored as a SparseTensor.\n",
        "\n",
        "We will load the test meshes from the test [tf.data.TFRecordDataset](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset)\n",
        "downloaded above. Each mesh is stored as a\n",
        "[tf.Example](https://www.tensorflow.org/api_docs/python/tf/train/Example), with\n",
        "the following fields:\n",
        "\n",
        "*   'num_vertices': Number of vertices in each mesh.\n",
        "*   'num_triangles': Number of triangles in each mesh.\n",
        "*   'vertices': A [V, 3] float tensor of vertex positions.\n",
        "*   'triangles': A [T, 3] integer tensor of vertex indices for each triangle.\n",
        "*   'labels': A [V] integer tensor with segmentation class label for each\n",
        "    vertex.\n",
        "\n",
        "where 'V' is number of vertices and 'T' is number of triangles in the mesh. As\n",
        "each mesh may have a varying number of vertices and faces (and the corresponding\n",
        "connectivity matrix), we pad the data tensors with '0's in each batch.\n",
        "\n",
        "For details on the dataset pipeline implementation, take a look at\n",
        "mesh_segmentation_dataio.py.\n",
        "\n",
        "Let's try to load a batch from the test TFRecordDataset, and visualize the first\n",
        "mesh with each vertex colored by the part label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZM02o0pEny6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834f18c9-0604-498b-c4d1-2e1449464454"
      },
      "source": [
        "test_io_params = {\n",
        "    'is_training': False,\n",
        "    'sloppy': False,\n",
        "    'shuffle': True,\n",
        "}\n",
        "test_tfrecords = test_data_files\n",
        "\n",
        "\n",
        "input_graph = tf.Graph()\n",
        "with input_graph.as_default():\n",
        "  mesh_load_op = dataio.create_input_from_dataset(\n",
        "      dataio.create_dataset_from_tfrecords, test_tfrecords, test_io_params)\n",
        "  with tf.Session() as sess:\n",
        "    test_mesh_data, test_labels = sess.run(mesh_load_op)\n",
        "\n",
        "# input_mesh_data = {\n",
        "#     'vertices': test_mesh_data['vertices'][0, ...],\n",
        "#     'faces': test_mesh_data['triangles'][0, ...],\n",
        "#     'vertex_colors': mesh_viewer.SEGMENTATION_COLORMAP[test_labels[0, ...]],\n",
        "# }\n",
        "# print(\"num of vertices slices: \",len(test_mesh_data['vertices'][0]),\"read from file: \",test_mesh_data['num_vertices'])\n",
        "# print(input_mesh_data)\n",
        "# print(type(input_mesh_data))\n",
        "# print()\n",
        "# input_viewer = mesh_viewer.Viewer(input_mesh_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_graphics/notebooks/mesh_segmentation_dataio.py:173: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMGltNkqBglZ",
        "outputId": "31532ccd-9d9d-4db3-faa5-7444d3ef6fae"
      },
      "source": [
        "print(test_mesh_data['num_vertices'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2652 2659 2654 2663 2660 2658 2665 2662]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er8lE1Re55La"
      },
      "source": [
        "for i in range(len(test_mesh_data['num_vertices'])):\n",
        "  myvertex = test_mesh_data['vertices'][i]\n",
        "  myface = test_mesh_data['triangles'][i]\n",
        "  num_vertex = test_mesh_data['num_vertices'][i]\n",
        "  num_face = test_mesh_data['num_triangles'][i]\n",
        "  outfile = 'OFF\\n'+ str(num_vertex) +' '+ str(num_face)+' '+ str(num_vertex+num_face-2) + '\\n'\n",
        "  for j in range(num_vertex):\n",
        "    outfile += str(myvertex[j][0]) + ' '+str(myvertex[j][1]) + ' '+str(myvertex[j][2]) + '\\n'\n",
        "  for j in range(num_face):\n",
        "    outfile += '3 '+str(myface[j][0])+' '+str(myface[j][1])+' '+str(myface[j][2])+'\\n'\n",
        "  myfile = open('/content/drive/MyDrive/mesh_seg/data/Dancer_test_sequence'+str(i)+'.off','w')\n",
        "  myfile.write(outfile)\n",
        "  myfile.close()\n",
        "# vertex0 = test_mesh_data['vertices'][0]\n",
        "# face0 = test_mesh_data['triangles'][0]\n",
        "# num_vertex0 = test_mesh_data['num_vertices'][0]\n",
        "# num_faces0 = test_mesh_data['num_triangles'][0]\n",
        "# print(len(vertex0),len(face0))\n",
        "# print(test_mesh_data['num_vertices'][0],test_mesh_data['num_triangles'][0])\n",
        "# outfile = 'OFF\\n'+ str(num_vertex0) +' '+ str(num_faces0)+' '+ str(num_vertex0+num_faces0-2) + '\\n'\n",
        "# for i in range(num_vertex0):\n",
        "#   outfile += str(vertex0[i][0]) + ' '+str(vertex0[i][1]) + ' '+str(vertex0[i][2]) + '\\n'\n",
        "# # print(outfile)\n",
        "# # outfile = ''\n",
        "# for i in range(num_faces0):\n",
        "#   outfile += '3 '+ str(face0[i][0]) + ' '+str(face0[i][1]) + ' '+str(face0[i][2]) + '\\n'\n",
        "# print(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCISqKdn9Qmd"
      },
      "source": [
        "# myfile = open('/content/drive/MyDrive/mesh_seg/data/mymodel0.off','w')\n",
        "# myfile.write(outfile)\n",
        "# myfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}